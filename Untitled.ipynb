{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba488ef-5e4b-4230-92af-0751480f9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn.mass_downloader import (\n",
    "    RectangularDomain, Restrictions, MassDownloader\n",
    ")\n",
    "from http.client import IncompleteRead\n",
    "from obspy.clients.fdsn.header import FDSNException\n",
    "\n",
    "def get_java_earthquake_catalog(start_date, end_date, region_params, max_retries=5, chunk_size=100):\n",
    "    client = Client(\"IRIS\", timeout=120)\n",
    "    catalog = obspy.Catalog()\n",
    "    offset = 0\n",
    "    while True:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                chunk = client.get_events(\n",
    "                    starttime=start_date,\n",
    "                    endtime=end_date,\n",
    "                    minlatitude=region_params['min_lat'],\n",
    "                    maxlatitude=region_params['max_lat'],\n",
    "                    minlongitude=region_params['min_lon'],\n",
    "                    maxlongitude=region_params['max_lon'],\n",
    "                    orderby=\"time\",\n",
    "                    limit=chunk_size,\n",
    "                    offset=offset\n",
    "                )\n",
    "                catalog += chunk\n",
    "                offset += chunk_size\n",
    "                if len(chunk) < chunk_size:\n",
    "                    return catalog\n",
    "                break\n",
    "            except (IncompleteRead, FDSNException):\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** attempt)\n",
    "                else:\n",
    "                    return catalog\n",
    "        else:\n",
    "            break\n",
    "    return catalog\n",
    "\n",
    "def download_event_data(event, base_dir, retries=3):\n",
    "    event_id = str(event.resource_id).split('/')[-1]\n",
    "    event_dir = os.path.join(base_dir, f\"event_{event_id}\")\n",
    "    origin = event.preferred_origin() or event.origins[0]\n",
    "    domain = RectangularDomain(\n",
    "        minlatitude=origin.latitude - 2,\n",
    "        maxlatitude=origin.latitude + 2,\n",
    "        minlongitude=origin.longitude - 2,\n",
    "        maxlongitude=origin.longitude + 2\n",
    "    )\n",
    "    restrictions = Restrictions(\n",
    "        starttime=origin.time - 60,\n",
    "        endtime=origin.time + 300,\n",
    "        reject_channels_with_gaps=True,\n",
    "        minimum_length=0.85,\n",
    "        channel_priorities=[\"HH[ZNE]\", \"BH[ZNE]\", \"HN[ZNE]\"],\n",
    "        location_priorities=[\"\", \"00\", \"10\"]\n",
    "    )\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "            mdl.download(\n",
    "                domain,\n",
    "                restrictions,\n",
    "                mseed_storage=os.path.join(event_dir, \"waveforms\"),\n",
    "                stationxml_storage=os.path.join(event_dir, \"stations\")\n",
    "            )\n",
    "            print(f\"Downloaded data for event {event_id}\")\n",
    "            return True\n",
    "        except (IncompleteRead, FDSNException):\n",
    "            if os.path.exists(event_dir):\n",
    "                for f in os.listdir(event_dir):\n",
    "                    os.remove(os.path.join(event_dir, f))\n",
    "                os.rmdir(event_dir)\n",
    "            time.sleep(2 ** attempt)\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    config = {\n",
    "        'region': {\n",
    "            'min_lat': -10.0,\n",
    "            'max_lat': -5.0,\n",
    "            'min_lon': 100.0,\n",
    "            'max_lon': 120.0\n",
    "        },\n",
    "        'time_range': {\n",
    "            'start': UTCDateTime(\"2021-06-17T06:11:00\"),\n",
    "            'end': UTCDateTime(\"2025-04-11T04:14:00\")\n",
    "        },\n",
    "        'output_dir': \"Final_java_earthquake_data\",\n",
    "        'max_events': 300\n",
    "    }\n",
    "    os.makedirs(config['output_dir'], exist_ok=True)\n",
    "    catalog = get_java_earthquake_catalog(\n",
    "        config['time_range']['start'],\n",
    "        config['time_range']['end'],\n",
    "        config['region']\n",
    "    )\n",
    "    catalog.events = sorted(catalog, \n",
    "        key=lambda x: x.origins[0].time, \n",
    "        reverse=True\n",
    "    )[:config['max_events']]\n",
    "    catalog_file = os.path.join(config['output_dir'], \"event_catalog.xml\")\n",
    "    catalog.write(catalog_file, format=\"QUAKEML\")\n",
    "    for i, event in enumerate(catalog):\n",
    "        if download_event_data(event, config['output_dir']):\n",
    "            pass  # The print is inside download_event_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc2e99-1dfc-4515-9768-1481236f19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import obspy\n",
    "# import logging\n",
    "# from obspy import UTCDateTime\n",
    "# from obspy.clients.fdsn import Client\n",
    "# from obspy.clients.fdsn.mass_downloader import (\n",
    "#     RectangularDomain, Restrictions, MassDownloader\n",
    "# )\n",
    "# from http.client import IncompleteRead\n",
    "# from obspy.clients.fdsn.header import FDSNException\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#     handlers=[logging.FileHandler('earthquake_download.log'), logging.StreamHandler()]\n",
    "# )\n",
    "\n",
    "# def get_java_earthquake_catalog(start_date, end_date, region_params, max_retries=5, chunk_size=100):\n",
    "#     \"\"\"\n",
    "#     Retrieve earthquake catalog with pagination and error handling\n",
    "#     \"\"\"\n",
    "#     client = Client(\"IRIS\", timeout=120)\n",
    "#     catalog = obspy.Catalog()\n",
    "#     offset = 0\n",
    "    \n",
    "#     while True:\n",
    "#         for attempt in range(max_retries):\n",
    "#             try:\n",
    "#                 chunk = client.get_events(\n",
    "#                     starttime=start_date,\n",
    "#                     endtime=end_date,\n",
    "#                     minlatitude=region_params['min_lat'],\n",
    "#                     maxlatitude=region_params['max_lat'],\n",
    "#                     minlongitude=region_params['min_lon'],\n",
    "#                     maxlongitude=region_params['max_lon'],\n",
    "#                     orderby=\"time\",\n",
    "#                     limit=chunk_size,\n",
    "#                     offset=offset\n",
    "#                 )\n",
    "#                 catalog += chunk\n",
    "#                 offset += chunk_size\n",
    "#                 logging.info(f\"Retrieved {len(chunk)} events (total: {len(catalog)})\")\n",
    "#                 if len(chunk) < chunk_size:\n",
    "#                     return catalog\n",
    "#                 break\n",
    "#             except (IncompleteRead, FDSNException) as e:\n",
    "#                 logging.warning(f\"Attempt {attempt+1} failed: {str(e)}\")\n",
    "#                 if attempt < max_retries - 1:\n",
    "#                     delay = 2 ** attempt\n",
    "#                     logging.info(f\"Retrying in {delay} seconds...\")\n",
    "#                     time.sleep(delay)\n",
    "#                 else:\n",
    "#                     logging.error(\"Max retries reached for catalog download\")\n",
    "#                     return catalog\n",
    "#         else:\n",
    "#             break\n",
    "#     return catalog\n",
    "\n",
    "# def download_event_data(event, base_dir, retries=3):\n",
    "#     \"\"\"\n",
    "#     Download waveform data for a single event with retries\n",
    "#     \"\"\"\n",
    "#     event_id = str(event.resource_id).split('/')[-1]\n",
    "#     event_dir = os.path.join(base_dir, f\"event_{event_id}\")\n",
    "#     origin = event.preferred_origin() or event.origins[0]\n",
    "    \n",
    "#     domain = RectangularDomain(\n",
    "#         minlatitude=origin.latitude - 2,\n",
    "#         maxlatitude=origin.latitude + 2,\n",
    "#         minlongitude=origin.longitude - 2,\n",
    "#         maxlongitude=origin.longitude + 2\n",
    "#     )\n",
    "    \n",
    "#     restrictions = Restrictions(\n",
    "#         starttime=origin.time - 60,\n",
    "#         endtime=origin.time + 300,\n",
    "#         reject_channels_with_gaps=True,\n",
    "#         minimum_length=0.85,\n",
    "#         channel_priorities=[\"HH[ZNE]\", \"BH[ZNE]\", \"HN[ZNE]\"],\n",
    "#         location_priorities=[\"\", \"00\", \"10\"]\n",
    "#     )\n",
    "    \n",
    "#     for attempt in range(retries):\n",
    "#         try:\n",
    "#             mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "#             mdl.download(\n",
    "#                 domain,\n",
    "#                 restrictions,\n",
    "#                 mseed_storage=os.path.join(event_dir, \"waveforms\"),\n",
    "#                 stationxml_storage=os.path.join(event_dir, \"stations\")\n",
    "#             )\n",
    "#             logging.info(f\"Successfully downloaded {event_id}\")\n",
    "#             return True\n",
    "#         except (IncompleteRead, FDSNException) as e:\n",
    "#             logging.warning(f\"Attempt {attempt+1} failed for {event_id}: {str(e)}\")\n",
    "#             if os.path.exists(event_dir):\n",
    "#                 for f in os.listdir(event_dir):\n",
    "#                     os.remove(os.path.join(event_dir, f))\n",
    "#                 os.rmdir(event_dir)\n",
    "#             time.sleep(2 ** attempt)\n",
    "#     logging.error(f\"Failed to download {event_id} after {retries} attempts\")\n",
    "#     return False\n",
    "\n",
    "# def main():\n",
    "#     # Configuration parameters\n",
    "#     config = {\n",
    "#         'region': {\n",
    "#             'min_lat': -10.0,\n",
    "#             'max_lat': -5.0,\n",
    "#             'min_lon': 100.0,\n",
    "#             'max_lon': 120.0\n",
    "#         },\n",
    "#         'time_range': {\n",
    "#             'start': UTCDateTime(\"2021-06-17T06:11:00\"),\n",
    "#             'end': UTCDateTime(\"2025-04-11T04:14:00\")\n",
    "#         },\n",
    "#         'output_dir': \"java_earthquake_data\",\n",
    "#         'max_events': 300\n",
    "#     }\n",
    "    \n",
    "#     # Create output directory\n",
    "#     os.makedirs(config['output_dir'], exist_ok=True)\n",
    "    \n",
    "#     # Get earthquake catalog\n",
    "#     logging.info(\"Starting catalog retrieval...\")\n",
    "#     catalog = get_java_earthquake_catalog(\n",
    "#         config['time_range']['start'],\n",
    "#         config['time_range']['end'],\n",
    "#         config['region']\n",
    "#     )\n",
    "    \n",
    "#     # Select most recent events\n",
    "#     catalog.events = sorted(catalog, \n",
    "#         key=lambda x: x.origins[0].time, \n",
    "#         reverse=True\n",
    "#     )[:config['max_events']]\n",
    "    \n",
    "#     # Save catalog\n",
    "#     catalog_file = os.path.join(config['output_dir'], \"event_catalog.xml\")\n",
    "#     catalog.write(catalog_file, format=\"QUAKEML\")\n",
    "#     logging.info(f\"Catalog saved to {catalog_file}\")\n",
    "    \n",
    "#     # Download waveform data\n",
    "#     logging.info(f\"Starting waveform download for {len(catalog)} events...\")\n",
    "#     success_count = 0\n",
    "#     for i, event in enumerate(catalog):\n",
    "#         logging.info(f\"Processing event {i+1}/{len(catalog)}\")\n",
    "#         if download_event_data(event, config['output_dir']):\n",
    "#             success_count += 1\n",
    "    \n",
    "#     logging.info(f\"Download completed. {success_count}/{len(catalog)} events downloaded successfully\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
